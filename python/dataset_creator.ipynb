{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_datasets = pd.read_csv('DataRescueProject_datasets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset               object\n",
       "status                object\n",
       "url                   object\n",
       "source_website        object\n",
       "organization          object\n",
       "agency                object\n",
       "download_date         object\n",
       "size                  object\n",
       "maintainer            object\n",
       "download_location     object\n",
       "file_type             object\n",
       "notes                 object\n",
       "metadata_available      bool\n",
       "metadata_url          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drp_datasets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>status</th>\n",
       "      <th>url</th>\n",
       "      <th>source_website</th>\n",
       "      <th>organization</th>\n",
       "      <th>agency</th>\n",
       "      <th>download_date</th>\n",
       "      <th>size</th>\n",
       "      <th>maintainer</th>\n",
       "      <th>download_location</th>\n",
       "      <th>file_type</th>\n",
       "      <th>notes</th>\n",
       "      <th>metadata_available</th>\n",
       "      <th>metadata_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Billion-Dollar Weather and Climate Disasters</td>\n",
       "      <td>Finished</td>\n",
       "      <td>https://www.ncei.noaa.gov/access/billions/mapping</td>\n",
       "      <td>ncei.noaa.gov</td>\n",
       "      <td>National Oceanic and Atmospheric Administration</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://dataverse.harvard.edu/dataset.xhtml?pe...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLS Downloads</td>\n",
       "      <td>Finished</td>\n",
       "      <td>https://download.bls.gov</td>\n",
       "      <td>download.bls.gov</td>\n",
       "      <td>Bureau of Labor Statistics</td>\n",
       "      <td>Department of Labor</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>47.00GB</td>\n",
       "      <td>DRP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDC FTP</td>\n",
       "      <td>Finished</td>\n",
       "      <td>https://ftp.cdc.gov/</td>\n",
       "      <td>ftp.cdc.gov</td>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Department of Health and Human Services</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>213.00GB</td>\n",
       "      <td>DRP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US Census Bureau FTP</td>\n",
       "      <td>Finished</td>\n",
       "      <td>ftp://ftp.census.gov</td>\n",
       "      <td>census.gov</td>\n",
       "      <td>Census Bureau</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>180.00GB</td>\n",
       "      <td>DRP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Partial download, server is back online but co...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Hurricane Center</td>\n",
       "      <td>Finished</td>\n",
       "      <td>https://www.nhc.noaa.gov/archive</td>\n",
       "      <td>nhc.noaa.gov</td>\n",
       "      <td>NOAA/National Hurricane Center</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>61.00GB</td>\n",
       "      <td>DRP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dataset    status  \\\n",
       "0  Billion-Dollar Weather and Climate Disasters  Finished   \n",
       "1                                 BLS Downloads  Finished   \n",
       "2                                       CDC FTP  Finished   \n",
       "3                          US Census Bureau FTP  Finished   \n",
       "4                     National Hurricane Center  Finished   \n",
       "\n",
       "                                                 url    source_website  \\\n",
       "0  https://www.ncei.noaa.gov/access/billions/mapping     ncei.noaa.gov   \n",
       "1                           https://download.bls.gov  download.bls.gov   \n",
       "2                               https://ftp.cdc.gov/       ftp.cdc.gov   \n",
       "3                               ftp://ftp.census.gov        census.gov   \n",
       "4                   https://www.nhc.noaa.gov/archive      nhc.noaa.gov   \n",
       "\n",
       "                                      organization  \\\n",
       "0  National Oceanic and Atmospheric Administration   \n",
       "1                       Bureau of Labor Statistics   \n",
       "2       Centers for Disease Control and Prevention   \n",
       "3                                    Census Bureau   \n",
       "4                   NOAA/National Hurricane Center   \n",
       "\n",
       "                                    agency download_date      size maintainer  \\\n",
       "0                   Department of Commerce                                      \n",
       "1                      Department of Labor    2025-02-01   47.00GB        DRP   \n",
       "2  Department of Health and Human Services    2025-02-01  213.00GB        DRP   \n",
       "3                   Department of Commerce    2025-02-01  180.00GB        DRP   \n",
       "4                   Department of Commerce    2025-02-06   61.00GB        DRP   \n",
       "\n",
       "                                   download_location file_type  \\\n",
       "0  https://dataverse.harvard.edu/dataset.xhtml?pe...             \n",
       "1                                                                \n",
       "2                                                                \n",
       "3                                                                \n",
       "4                                                                \n",
       "\n",
       "                                               notes  metadata_available  \\\n",
       "0                                                                  False   \n",
       "1                                                                  False   \n",
       "2                                                                  False   \n",
       "3  Partial download, server is back online but co...               False   \n",
       "4                                                                  False   \n",
       "\n",
       "  metadata_url  \n",
       "0               \n",
       "1               \n",
       "2               \n",
       "3               \n",
       "4               "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drp_datasets.columns = drp_datasets.columns.str.lower()\n",
    "drp_datasets = drp_datasets.fillna('')\n",
    "drp_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def slugify(string):\n",
    "    string = clean_text(string)\n",
    "    # Remove special characters\n",
    "    string = re.sub(r'[^\\w\\s-]', '', string)\n",
    "    # Replace spaces with hyphens\n",
    "    string = re.sub(r'\\s+', '-', string)\n",
    "    # Convert to lowercase\n",
    "    string = string.lower()\n",
    "    return string\n",
    "\n",
    "def clean_text(string):\n",
    "    # Remove leading '-'\n",
    "    string = re.sub(r'^-', '', string)\n",
    "    # Replace ':' with '-'\n",
    "    string = string.replace(':', '-')\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_md(row):\n",
    "    ## Defining the schema, filename and path\n",
    "    schema = 'data_rescue_project'\n",
    "    dataset_filename = slugify(row['dataset'])\n",
    "    datset_path = \"../_datasets\"\n",
    "    org_filename = slugify(row['organization'])\n",
    "    org_path = \"../_organizations\"\n",
    "\n",
    "    ## Creating the dataset markdown file\n",
    "    dataset_md = \"---\\n\"\n",
    "    dataset_md += f\"schema: {schema} \\n\"\n",
    "    dataset_md += f\"title: {clean_text(row['dataset'])}\\n\"\n",
    "    dataset_md += f\"organization: {clean_text(row['organization'])}\\n\"\n",
    "    dataset_md += f\"agency: {clean_text(row['agency'])}\\n\"\n",
    "    dataset_md += f\"notes: {clean_text(row['notes'])}\\n\"\n",
    "    dataset_md += f\"status: {clean_text(row['status'])}\\n\"\n",
    "    dataset_md += f\"size: {clean_text(row['size'])}\\n\"\n",
    "    dataset_md += f\"maintainer: {clean_text(row['maintainer'])}\\n\"\n",
    "    dataset_md += f\"download_date: {clean_text(row['download_date'])}\\n\"\n",
    "    dataset_md += f\"metadata_available: {str(row['metadata_available'])}\\n\"\n",
    "    dataset_md += f\"metadata_url: {row['metadata_url']}\\n\"\n",
    "    dataset_md += f\"resources:\\n\"\n",
    "    dataset_md += f\"  - name: Data Source\\n\"\n",
    "    dataset_md += f\"    url: {row['url']}\\n\"\n",
    "    dataset_md += f\"    format: html\\n\"\n",
    "    dataset_md += f\"  - name: Link to archive\\n\"\n",
    "    dataset_md += f\"    url: {row['download_location']}\\n\"\n",
    "    dataset_md += f\"    format: {row['file_type']}\\n\"\n",
    "    dataset_md += \"---\\n\"\n",
    "\n",
    "    ## Writing the dataset markdown file\n",
    "    with open(f'{path}/{filename}.md', 'w') as output:\n",
    "      output.write(dataset_md)\n",
    "    \n",
    "    ## Creating the organization markdown file\n",
    "    org_md = \"---\\n\"\n",
    "    org_md += f\"title: {clean_text(row['organization'])} \\n\" \n",
    "    org_md += f\"description: \\n\" \n",
    "    org_md = \"---\\n\"\n",
    "\n",
    "    ## Writing the organization markdown file\n",
    "    with open(f'{org_path}/{org_filename}.md', 'w') as output:\n",
    "      output.write(org_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "355    None\n",
       "356    None\n",
       "357    None\n",
       "358    None\n",
       "359    None\n",
       "Length: 360, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drp_datasets.apply(create_dataset_md, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mdataset_test.md\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_dataset_md\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrp_datasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "with open('dataset_test.md', 'w') as output:\n",
    "    output.write(create_dataset_md(drp_datasets.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
